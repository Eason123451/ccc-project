{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd251f68-1499-41a5-9495-05463e977616",
   "metadata": {},
   "source": [
    "# Assignment 3 - Blood Managment\n",
    "\n",
    "Note: you will need packages `cvxopt` and `glpk`for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5d30bff-ec26-4189-b3b2-b2f302783cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import cvxopt\n",
    "from collections import (namedtuple, defaultdict)\n",
    "import os.path\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf0339e-e261-4d98-9c70-d84017f89022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"http://elastic:epheli0AJ4eir9xaiM2muqu6eehee4oh@localhost:5601/app/visualize#/edit/182df070-1350-11ef-8686-113897a9ab0e?_g=(filters%3A!()%2CrefreshInterval%3A(pause%3A!t%2Cvalue%3A0)%2Ctime%3A(from%3A'2021-06-08T08%3A04%3A24.457Z'%2Cto%3A'2021-08-01T02%3A20%3A58.344Z'))\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1325f3d5fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "kibana_iframe_url = \"http://elastic:epheli0AJ4eir9xaiM2muqu6eehee4oh@localhost:5601/app/visualize#/edit/182df070-1350-11ef-8686-113897a9ab0e?_g=(filters%3A!()%2CrefreshInterval%3A(pause%3A!t%2Cvalue%3A0)%2Ctime%3A(from%3A'2021-06-08T08%3A04%3A24.457Z'%2Cto%3A'2021-08-01T02%3A20%3A58.344Z'))\"\n",
    "IFrame(src=kibana_iframe_url, width='800', height='600')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ad83f2-988d-4480-bcf3-b3003666846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elapsed_since(start):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start))\n",
    "\n",
    "\n",
    "def get_process_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.get_memory_info().rss\n",
    "\n",
    "\n",
    "def track(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        mem_before = get_process_memory()\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed_time = elapsed_since(start)\n",
    "        mem_after = get_process_memory()\n",
    "        print(\"{}: memory before: {:,}, after: {:,}, consumed: {:,}; exec time: {}\".format(\n",
    "            func.__name__,\n",
    "            mem_before, mem_after, mem_after - mem_before,\n",
    "            elapsed_time))\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def printParams(params):\n",
    "    print(params) \n",
    "        \n",
    "\n",
    "def loadParams(param_dict):\n",
    "\n",
    "    # parDf = pd.read_excel(filename, sheet_name = 'Parameters')\n",
    "\n",
    "    # # print(parDf)\n",
    "    \n",
    "    # parDict=parDf.set_index('Index').T.to_dict('list')\n",
    "\n",
    "    parDict = {i: [param_dict[i]] for i in param_dict.keys()}\n",
    "    \n",
    "    params = {key:v for key, value in parDict.items() for v in value}\n",
    "\n",
    "    params['PRINT']=False\n",
    "    params['PRINT_ALL']=False\n",
    "    params['OUTPUT_FILENAME'] = 'DetailedOutput.xlsx'\n",
    "\n",
    "    # params['SHOW_PLOTS']=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Set here bloodtypes and substitutions that are allowed\n",
    "    params['Bloodtypes'] = ['AB+', 'AB-', 'A+', 'A-','B+', 'B-', 'O+', 'O-'] \n",
    "    params['NUM_BLD_TYPES'] = len(params['Bloodtypes'])\n",
    "\n",
    "    b = [(x,y) for x in params['Bloodtypes'] for y in params['Bloodtypes']]\n",
    "    f = [False]*(len(params['Bloodtypes'])*len(params['Bloodtypes']))\n",
    "    c = {k:v for k,v in zip(b, f)}\n",
    "    #In case we want to allow subs\n",
    "    c[('AB+', 'AB+')] = True\n",
    "\n",
    "    c[('AB-', 'AB+')] = True\n",
    "    c[('AB-', 'AB-')] = True\n",
    "\n",
    "    c[('A+', 'AB+')] = True\n",
    "    c[('A+', 'A+')] = True\n",
    "\n",
    "    c[('A-', 'AB+')] = True\n",
    "    c[('A-', 'AB-')] = True\n",
    "    c[('A-', 'A+')] = True\n",
    "    c[('A-', 'A-')] = True\n",
    "\n",
    "    c[('B+', 'AB+')] = True\n",
    "    c[('B+', 'B+')] = True\n",
    "\n",
    "    c[('B-', 'AB+')] = True\n",
    "    c[('B-', 'AB-')] = True\n",
    "    c[('B-', 'B+')] = True\n",
    "    c[('B-', 'B-')] = True\n",
    "\n",
    "    c[('O+', 'AB+')] = True\n",
    "    c[('O+', 'A+')] = True\n",
    "    c[('O+', 'B+')] = True\n",
    "    c[('O+', 'O+')] = True\n",
    "\n",
    "    c[('O-', 'AB+')] = True\n",
    "    c[('O-', 'A+')] = True\n",
    "    c[('O-', 'B+')] = True\n",
    "    c[('O-', 'O+')] = True\n",
    "    c[('O-', 'AB-')] = True\n",
    "    c[('O-', 'A-')] = True\n",
    "    c[('O-', 'B-')] = True\n",
    "    c[('O-', 'O-')] = True\n",
    "    params['SubMatrix'] = c\n",
    "\n",
    "    # Set here max age of blood\n",
    "    params['MAX_AGE'] = 3\n",
    "    params['Ages'] = list(range(params['MAX_AGE']))\n",
    "\n",
    "    params['NUM_BLD_NODES'] = params['NUM_BLD_TYPES'] * params['MAX_AGE']\n",
    "\n",
    "    # Set here blood demand nodes\n",
    "    params['Surgerytypes'] = ['Urgent', 'Elective']\n",
    "    params['Substitution'] = [True]\n",
    "\n",
    "    params['NUM_SUR_TYPES'] = len(params['Surgerytypes'])\n",
    "    params['NUM_DEM_NODES'] = params['NUM_BLD_TYPES'] * params['NUM_SUR_TYPES'] * len(params['Substitution'])\n",
    "\n",
    "\n",
    "    # Solver params\n",
    "    params['SLOPE_CAPAC_LAST'] = 100000\n",
    "    params['MIN_CONST'] = 0.01\n",
    "    params['EPSILON'] = 0.001\n",
    "\n",
    "\n",
    "    # Set here number of iterations and time periods\n",
    "    params['NUM_TRAINNING_ITER'] = int(params['NUM_TRAINNING_ITER'])\n",
    "    params['NUM_TESTING_ITER']=int(params['NUM_TESTING_ITER'])\n",
    "    params['NUM_ITER'] = int(params['NUM_TESTING_ITER'] + params['NUM_TRAINNING_ITER']) #Total number of iterations\n",
    "    params['MAX_TIME']=int(15)\n",
    "    params['Times'] = list(range(params['MAX_TIME']))\n",
    "\n",
    "    # Set here VFA parameters\n",
    "    # - If USE_VFA is set to True we are going to use VFA's when making the decisions - \n",
    "    # - If USE_VFA is set to False, it means that a  MYOPIC policy is going to be considered and all the parameters\n",
    "    #related to VFA's (such as DISCOUNT_FACTOR, LOAD_VFA, SAVE_VFA, STEPSIZE_RULE, PROJECTION_ALGO, \n",
    "    #IS_PERTUB,SEED_TRAINING are ignored)\n",
    "    #params['USE_VFA'] = True #If set to True we are going to use VFA's when making the decisions - False means a MYOPIC policy\n",
    "    params['DISCOUNT_FACTOR'] = 0.95\n",
    "\n",
    "    params['LOAD_VFA'] = False #If set to True we are going to initialize the VFA's with VFA's from previous runs - instead of all zeros\n",
    "    params['NAME_LOAD_VFA_PICKLE'] = \"Bld_Net10_P_C_Subs.pickle\"\n",
    "    params['SAVE_VFA'] = False #If we want to save/update the VFA's to be used in future runs\n",
    "    params['NAME_SAVE_VFA_PICKLE'] = \"Bld_Net10_P_C_Subs.pickle\"\n",
    "\n",
    "    # Set here the stepsize parameters\n",
    "    params['STEPSIZE_RULE'] = 'C' #Possible values: 'C' for Constant or 'A' for AdaGrad\n",
    "    params['NUM_ITER_STEP_ONE'] = 0 #Number of iterations with stepsize one \n",
    "\n",
    "    # Set here the CONSTANT stepsize parameter (not considered if AdaGrad stepsize is being used)\n",
    "    #params['ALPHA'] = 0.2 #the stepsize for the other iterations\n",
    "\n",
    "    #Set here the AdaGrad stepsize parameters (not considered if Constant stepsize is being used)\n",
    "    params['STEP_EPS'] = 0.00000001\n",
    "    params['ETA'] = 1\n",
    "\n",
    "    # Set here the algorithm that should be use for projection back the slopes that break concavity\n",
    "    # Possible algorithms for projecting back the slopes to enforce concavity are:\n",
    "    # - 'Avg' to average the slopes that break concavity; \\\n",
    "    # - 'Copy' to copy the newly updated vbar to the slopes that break concavity\n",
    "    # - 'Up' to update the slopes that break concavity with the current stepsize and vhat \n",
    "    params['PROJECTION_ALGO'] = 'Up' \n",
    "\n",
    "\n",
    "    #Perturb the solution during training iterations for exploration\n",
    "    params['IS_PERTUB'] = False\n",
    "    params['LAMBDA_PERTUB'] = 1\n",
    "    params['PERTUB_GEN'] = np.random.RandomState(13247)\n",
    "\n",
    "    # Set here one step contribution function parameters  - BONUSES and PENALTIES \n",
    "    params['AGE_BONUS']=np.zeros(params['MAX_AGE'])\n",
    "    # params['AGE_BONUS']=[2]*MAX_AGE\n",
    "    # params['AGE_BONUS']=list(reversed(list(range(0,MAX_AGE))))\n",
    "    # params['AGE_BONUS']=list(range(0,MAX_AGE))\n",
    "    # params['AGE_BONUS']=[0.5, 2] #It has to be the same length as MAX_AGE\n",
    "\n",
    "    params['INFEASIABLE_SUBSTITUTION_PENALTY'] = -500000\n",
    "    params['NO_SUBSTITUTION_BONUS'] = 0\n",
    "\n",
    "    # Set here Random Seeds \n",
    "    params['SEED_TRAINING'] = 1090377\n",
    "    params['SEED_TESTING'] = 8090373\n",
    "\n",
    "    #Set here the distribution for demand/donation/initial inventory\n",
    "    params['SAMPLING_DIST'] = 'P' #Possible values: 'P' for Poisson or 'U' for uniform\n",
    "    params['POISSON_FACTOR'] = 1\n",
    "\n",
    "    # Set here max demand by blood type (when 'U'niform dist) or mean demand (when 'P'oisson dist) \n",
    "    params['DEFAULT_VALUE_DIST'] = 20\n",
    "    d = [params['DEFAULT_VALUE_DIST']] * params['NUM_BLD_TYPES']\n",
    "    params['MAX_DEM_BY_BLOOD'] = {k:v for k,v in zip(params['Bloodtypes'], d)}\n",
    "    params['MAX_DON_BY_BLOOD'] = {k:v for k,v in zip(params['Bloodtypes'], d)}\n",
    "\n",
    "\n",
    "    # Set here demand by blood type (for blood types that are different than the params['DEFAULT_VALUE_DIST'])\n",
    "    params['MAX_DEM_BY_BLOOD']['AB+'] = 3\n",
    "    params['MAX_DEM_BY_BLOOD']['B+'] = 9\n",
    "    params['MAX_DEM_BY_BLOOD']['O+'] = 18\n",
    "    params['MAX_DEM_BY_BLOOD']['B-'] = 2\n",
    "    params['MAX_DEM_BY_BLOOD']['AB-'] = 3\n",
    "    params['MAX_DEM_BY_BLOOD']['A-'] = 6\n",
    "    params['MAX_DEM_BY_BLOOD']['O-'] = 7\n",
    "    params['MAX_DEM_BY_BLOOD']['A+'] = 14\n",
    "\n",
    "    #params['DEFAULT_VALUE_DIST']\n",
    "\n",
    "    # Set here donation by blood type (for blood types that are different than the params['DEFAULT_VALUE_DIST'])\n",
    "    params['MAX_DON_BY_BLOOD']['AB+'] = 3\n",
    "    params['MAX_DON_BY_BLOOD']['B+'] = 9\n",
    "    params['MAX_DON_BY_BLOOD']['O+'] = 18\n",
    "    params['MAX_DON_BY_BLOOD']['B-'] = 2\n",
    "    params['MAX_DON_BY_BLOOD']['AB-'] = 3\n",
    "    params['MAX_DON_BY_BLOOD']['A-'] = 6\n",
    "    params['MAX_DON_BY_BLOOD']['O-'] = 7\n",
    "    params['MAX_DON_BY_BLOOD']['A+'] = 14\n",
    "\n",
    "\n",
    "    #The default weights to split the demand of a blood type is equal weights. The only requirement is that each\n",
    "    #weight is positive and they add up to 1. \n",
    "    #Default\n",
    "    params['SURGERYTYPES_PROP'] = {k:1/len(params['Surgerytypes']) for k in params['Surgerytypes']}\n",
    "    params['SUBSTITUTION_PROP'] = {k:1/len(params['Substitution']) for k in params['Substitution']}\n",
    "\n",
    "    # Set here the weights for each surgery type (if different than the default)\n",
    "    params['SURGERYTYPES_PROP']['Urgent'] = 1/2\n",
    "    params['SURGERYTYPES_PROP']['Elective'] = 1 - params['SURGERYTYPES_PROP']['Urgent']\n",
    "\n",
    "    # Set here the weights for each substitution type (if different than the default)\n",
    "    params['SUBSTITUTION_PROP'][True] = 1\n",
    "    #params['SUBSTITUTION_PROP'][False] = 1 - params['SUBSTITUTION_PROP'][True]\n",
    "\n",
    "\n",
    "    #Set here random surge parameters\n",
    "    #params['TIME_PERIODS_SURGE'] = set([4,8,10,12,14])\n",
    "    params['TIME_PERIODS_SURGE'] = set([3,6,10,13])\n",
    "    #SURGE_PROB = 0.7\n",
    "    params['SURGE_FACTOR'] = 6 #The surge demand is always going to be poisson with mean SURGE_FACTOR*params['MAX_DEM_BY_BLOOD'], even if the regular demand distribution is Uniform\n",
    "\n",
    "    \n",
    "    #Set here the weights for the utility function - urgent coverage, elective coverage, proportion of blood discarded\n",
    "    params['WEIGHT_URGENT']= params['URGENT_DEMAND_BONUS']\n",
    "    params['WEIGHT_ELECTIVE']= params['ELECTIVE_DEMAND_BONUS']\n",
    "    params['WEIGHT_DISCARDED']= -1*params['DISCARD_BLOOD_PENALTY']\n",
    "\n",
    "    # params['URGENT_DEMAND_BONUS'] = 10\n",
    "    # params['ELECTIVE_DEMAND_BONUS'] = 1\n",
    "    # params['DISCARD_BLOOD_PENALTY'] = -3 #applied for the oldest age in the holding/vfa arcs\n",
    "\n",
    "\n",
    "    if (params['SAMPLING_DIST'] == 'P'):\n",
    "        params['MAX_DEM_BY_BLOOD'] = {k: int(v * params['POISSON_FACTOR']) for k, v in params['MAX_DEM_BY_BLOOD'].items()}\n",
    "        params['MAX_DON_BY_BLOOD'] = {k: int(v * params['POISSON_FACTOR']) for k, v in params['MAX_DON_BY_BLOOD'].items()}\n",
    "        \n",
    "        params['AVG_TOTAL_DEMAND'] = sum(params['MAX_DEM_BY_BLOOD'].values())\n",
    "        params['AVG_TOTAL_SUPPLY'] = sum(params['MAX_DON_BY_BLOOD'].values())\n",
    "        params['NUM_PARALLEL_LINKS'] = int(params['MAX_AGE']/2 * max(params['MAX_DON_BY_BLOOD'].values()))\n",
    "        #print(\"Exogenous info dist: Poisson \")\n",
    "    else:\n",
    "        params['AVG_TOTAL_DEMAND'] = sum(params['MAX_DEM_BY_BLOOD'].values())/2\n",
    "        params['AVG_TOTAL_SUPPLY'] = sum(params['MAX_DON_BY_BLOOD'].values())/2\n",
    "        params['NUM_PARALLEL_LINKS'] = int(params['MAX_AGE']/2 * max(params['MAX_DON_BY_BLOOD'].values()))\n",
    "        #print(\"Exogenous info dist: Uniform\")\n",
    "\n",
    "    #Checking if MYOPIC policy\n",
    "    if not params['USE_VFA']:\n",
    "        params['ALPHA'] = 0\n",
    "        params['LOAD_VFA'] = False\n",
    "        params['SAVE_VFA'] = False\n",
    "        params['NUM_TRAINNING_ITER'] = 0\n",
    "        params['NUM_ITER'] = params['NUM_TESTING_ITER']\n",
    "        params['NUM_PARALLEL_LINKS'] = 1    \n",
    "\n",
    "\n",
    "    # print(\"Printing params dict\\n\")\n",
    "    # printParams(params)\n",
    "\n",
    "\n",
    "    # if (params['SAMPLING_DIST'] == 'P'):\n",
    "    #      print(\"Exogenous info dist: Poisson \")\n",
    "    # else:\n",
    "    #     print(\"Exogenous info dist: Uniform\")\n",
    "    \n",
    "    # print(\"Demand parameters by blood type \",params['MAX_DEM_BY_BLOOD'])\n",
    "    # print(\"There are \",params['NUM_SUR_TYPES'] * len(params['Substitution']),\" demand nodes for each blood type\")\n",
    "    # print(\"Weights SURGERYTYPES_PROP \",params['SURGERYTYPES_PROP'])\n",
    "    # print(\"Weights SUBSTITUTION_PROP \",params['SUBSTITUTION_PROP'])\n",
    "\n",
    "    # print(\"Donation parameters by blood type \",params['MAX_DON_BY_BLOOD'])    \n",
    "\n",
    "    # print(\"AVG TOTAL DEMAND \",params['AVG_TOTAL_DEMAND'])\n",
    "    # print(\"AVG TOTAL SUPPLY \",params['AVG_TOTAL_SUPPLY'])\n",
    "    # print(\"NUM PARALLEL LINKS \",params['NUM_PARALLEL_LINKS'])\n",
    "\n",
    "\n",
    "    # print(\"Possible surge time periods \", params['TIME_PERIODS_SURGE'])\n",
    "    # print(\"SURGE_PROB \", params['SURGE_PROB'], \" and SURGE_FACTOR \", params['SURGE_FACTOR'])\n",
    "        \n",
    "        \n",
    "    return params \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def initOutputListHeaders(params):\n",
    "    labelsDemandExo=['Iteration','Time','Bloodtype','Urgency','isSubAllowed','DemandValue']\n",
    "    labelsDonationExo=['Iteration','Time','Bloodtype','DonationValue']\n",
    "    labelsSupplyPre=['Iteration','Time','BloodType','Age','PreInv']\n",
    "    labelsSupplyPost=['Iteration','Time','BloodType','Age','PostInv']\n",
    "\n",
    "    \n",
    "    labelsSlopesList=['Iteration','Time','BloodType','Age']\n",
    "    vNames = [\"v_\"+str(r) for r in list(range(params['NUM_PARALLEL_LINKS']))]\n",
    "    labelsSlopesList = labelsSlopesList + vNames\n",
    "   \n",
    "    headerSolDemList =['Iteration',  'Time','BloodTypeS', 'Age','BloodTypeD', 'Urgency', 'SubsAllowed', 'isCompatible',  'Contrib', 'Value']    \n",
    "    headerSolHoldList = ['Iteration','Time','BloodTypeS','Age','Value']  \n",
    "    headerSimuList = ['Iteration','ElapsedTime','Stepsize','ObjVal','isTrainning']  \n",
    "    headerUpdateVfaList = ['Iteration','Time','BloodType','Age','R','vhat','vbarOld','sqGrad','stepsize','vbarNew']\n",
    "    \n",
    "    return(labelsDemandExo, labelsDonationExo,labelsSupplyPre,labelsSupplyPost,labelsSlopesList,headerSolDemList,headerSolHoldList,headerSimuList,headerUpdateVfaList)\n",
    "\n",
    "\n",
    "def convertToDfOutputLists(params,Bld_Net,demandExoList, donationExoList, supplyPreList, supplyPostList, slopesList, solDemList, solHoldList,  simuList, updateVfaList):\n",
    "    labelsDemandExo, labelsDonationExo, labelsSupplyPre,  labelsSupplyPost, labelsSlopesList, headerSolDemList, headerSolHoldList, headerSimuList, headerUpdateVfaList = initOutputListHeaders(params)\n",
    "\n",
    "    #Flatteting the lists \n",
    "    dfSimu = pd.DataFrame.from_records(simuList,columns=headerSimuList)\n",
    "\n",
    "    demandExoListFlat = [(ite,t,dnode[0],dnode[1],dnode[2],dvalue) for ite,t,d in demandExoList for dnode,dvalue in zip(Bld_Net.demandnodes,d)]\n",
    "    dfDemandExo = pd.DataFrame.from_records(demandExoListFlat,columns=labelsDemandExo)\n",
    "\n",
    "    donationExoListFlat = [(ite,t,dtype,dvalue) for ite,t,d in donationExoList for dtype,dvalue in zip(params['Bloodtypes'],d)]\n",
    "    dfDonationExo = pd.DataFrame.from_records(donationExoListFlat,columns=labelsDonationExo)\n",
    "\n",
    "    supplyPreListFlat = [(ite,t,bnode[0],bnode[1],bvalue) for ite,t,b in supplyPreList for bnode,bvalue in zip(Bld_Net.bloodnodes,b)]\n",
    "    dfSupplyPre = pd.DataFrame.from_records(supplyPreListFlat,columns=labelsSupplyPre)\n",
    "\n",
    "\n",
    "    supplyPostListFlat = [(ite,t,bnode[0],bnode[1],bvalue) for ite,t,b in supplyPostList for bnode,bvalue in zip(Bld_Net.bloodnodes,b)]\n",
    "    dfSupplyPost = pd.DataFrame.from_records(supplyPostListFlat,columns=labelsSupplyPost)\n",
    "\n",
    "\n",
    "    solDemListFlat = [(ite,t,bld[0],bld[1],dem[0],dem[1],dem[2],params['SubMatrix'][(bld[0], dem[0])],Bld_Net.demweights[(bld,dem)],xbd) for ite,t,xDem in solDemList for bld,xb in zip(Bld_Net.bloodnodes,xDem) for dem,xbd in zip(Bld_Net.demandnodes,xb)]\n",
    "    dfSolDem = pd.DataFrame.from_records(solDemListFlat,columns=headerSolDemList)\n",
    "\n",
    "    solHoldListFlat = [(ite,t,bnode[0],bnode[1],hvalue) for ite,t,h in solHoldList for bnode,hvalue in zip(Bld_Net.bloodnodes,h)]\n",
    "    dfSolHold = pd.DataFrame.from_records(solHoldListFlat,columns=headerSolHoldList)\n",
    "\n",
    "\n",
    "    slopesListFlat = [(vnode[0],vnode[1],bnode[0],bnode[1],*list(vnode[2])) for vnode,bnode in zip(slopesList,Bld_Net.bloodnodes*params['NUM_ITER']*params['MAX_TIME'])]\n",
    "\n",
    "    dfSlopes = pd.DataFrame.from_records(slopesListFlat,columns=labelsSlopesList)\n",
    "\n",
    "    dfUpdateVfa = pd.DataFrame.from_records(updateVfaList,columns=headerUpdateVfaList)\n",
    "\n",
    "    return dfDemandExo, dfDonationExo, dfSupplyPre, dfSupplyPost, dfSlopes, dfSolDem, dfSolHold,  dfSimu, dfUpdateVfa\n",
    "\n",
    "def printDfsToOutputFile(params,dfDemandExo, dfDonationExo, dfSupplyPre, dfSupplyPost, dfSlopes, dfSolDem, dfSolHold,  dfSimu, dfUpdateVfa):\n",
    "\n",
    "    t_init_print = time.time()\n",
    "    print(\"Started printing file\")\n",
    "    # print to excel file\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(params['OUTPUT_FILENAME'], engine='xlsxwriter')\n",
    "\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    dfSimu.to_excel(writer, sheet_name='Simu')\n",
    "    \n",
    "    if params['PRINT_ALL']:\n",
    "        dfDemandExo.to_excel(writer, sheet_name='DemandExo')\n",
    "        dfDonationExo.to_excel(writer, sheet_name='DonationExo')\n",
    "        dfSupplyPre.to_excel(writer, sheet_name='SupplyPre')\n",
    "        dfSolDem.to_excel(writer, sheet_name='SolDem')\n",
    "        dfSolHold.to_excel(writer, sheet_name='HoldDem')\n",
    "        dfSupplyPost.to_excel(writer, sheet_name='SupplyPost')\n",
    "        dfSlopes.to_excel(writer, sheet_name='SlopesList')\n",
    "        dfUpdateVfa.to_excel(writer, sheet_name='UpdatesVfa')\n",
    "\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "\n",
    "    print(\"Finished printing files in {:.2f} secs\".format(time.time()-t_init_print))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad1cf217-ef1b-412c-8dae-c85d223c8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Main(param_dict):    \n",
    "    \n",
    "    t_global_init = time.time()\n",
    "    print(\"********************Started Main*****************\\n\")\n",
    "    # params = loadParams('Parameters.xlsx')\n",
    "    params = loadParams(param_dict)\n",
    "    # print(params)\n",
    "    alpha = params['ALPHA']\n",
    "    \n",
    "    #ite_TRA=np.arange(0, params['NUM_TRAINNING_ITER'], 1)\n",
    "    #selectedIte = list(set([0,5,10,19]) & set(ite_TRA))\n",
    "    \n",
    "    \n",
    "\n",
    "    # initializing the random seed for trainning iterations\n",
    "    np.random.seed(params['SEED_TRAINING'])\n",
    "\n",
    "    # initializing the blood network\n",
    "    Bld_Net = create_bld_net(params)\n",
    "\n",
    "    if (params['LOAD_VFA'] and os.path.exists(params['NAME_LOAD_VFA_PICKLE'])):\n",
    "        pickle_off = open(params['NAME_LOAD_VFA_PICKLE'],\"rb\")\n",
    "        Other_Bld_Net = pickle.load(pickle_off)\n",
    "        Bld_Net.varr = Other_Bld_Net.varr.copy()\n",
    "        Bld_Net.parallelarr = Other_Bld_Net.parallelarr.copy()\n",
    "\n",
    "    # initializing the model\n",
    "    state_names = ['BloodInventory', 'Demand', 'Donation']\n",
    "    decision_names = ['Hold', 'Contribution']  \n",
    "\n",
    "    # initializing the lists that will store the all the info/decisions/states/slopes along the iterations for printing purposes\n",
    "    demandExoList, donationExoList, supplyPreList, supplyPostList, slopesList, solDemList, solHoldList,  simuList, updateVfaList = [],[],[],[],[],[],[],[],[]\n",
    "\n",
    "    #initializing the policy\n",
    "    P = Policy(params,Bld_Net)\n",
    "\n",
    "    \n",
    "    iteration = 0\n",
    "    obj = []\n",
    "\n",
    "    # if (params['NUM_TRAINNING_ITER']>0):\n",
    "    #     print(\"\\n Starting training iterations\\n\")\n",
    "\n",
    "    while iteration < params['NUM_ITER']:  \n",
    "        IS_TRAINING = (iteration<params['NUM_TRAINNING_ITER'])\n",
    "        if (iteration==params['NUM_TRAINNING_ITER']):\n",
    "            # print(\"Starting testing iterations! Currently at iteration \",iteration)\n",
    "            # print(\"Reseting random seed!\")\n",
    "            np.random.seed(params['SEED_TESTING'])\n",
    "            \n",
    "        # t_init = time.clock()\n",
    "        t_init = time.process_time()\n",
    "        # print('Iteration = ', iteration)\n",
    "        \n",
    "        # Initial inventory\n",
    "        if (params['SAMPLING_DIST'] == 'P'):\n",
    "            bldinv_init = [int(np.random.poisson(params['MAX_DON_BY_BLOOD'][bld[0]])*.9) if bld[1]=='0' else int(np.random.poisson(params['MAX_DON_BY_BLOOD'][bld[0]])*(0.1/(params['MAX_AGE']-1))) for bld in Bld_Net.bloodnodes]\n",
    "        else:\n",
    "            bldinv_init = [round(np.random.uniform(0, params['MAX_DON_BY_BLOOD'][bld[0]])*.9) if bld[1]=='0' else round(np.random.uniform(0, params['MAX_DON_BY_BLOOD'][bld[0]])*(0.1/(params['MAX_AGE']-1))) for bld in Bld_Net.bloodnodes]\n",
    "    \n",
    "        # Initial exogenous information\n",
    "        if (params['SAMPLING_DIST'] == 'P'):\n",
    "            exog_info_init = generate_exog_info_by_bloodtype_p(0, Bld_Net, params)\n",
    "        else:\n",
    "            exog_info_init = generate_exog_info_by_bloodtype(0, Bld_Net, params)\n",
    "\n",
    "        #initial state - the donation is irrelevant at time period zero - only the initial invetory counts\n",
    "        init_state = {'BloodInventory': bldinv_init, 'Demand': exog_info_init.demand, 'Donation' : exog_info_init.donation}\n",
    "\n",
    "        M = Model(state_names, decision_names, init_state, Bld_Net,params)\n",
    "        #print(\"Initial blood supply across {} types and {} ages is {}\".format(params['NUM_BLD_TYPES'],params['MAX_AGE'],sum(M.bld_inv)))\n",
    "        #print(\"Initial demand across {} types and {} urgency states and {} substitution states is {}\".format(params['NUM_BLD_TYPES'],params['NUM_SUR_TYPES'],len(params['Substitution']),sum(M.demand)))\n",
    "\n",
    "        \n",
    "        t = 0        \n",
    "        obj.append(0)\n",
    "\n",
    "        #Steping forward in time\n",
    "        while t < params['MAX_TIME']:\n",
    "          \n",
    "            \n",
    "            #Compute the solution for time period t - return the solution, the value, the dual and the updated lists\n",
    "            sol,val,x,hld,d,solDemList,solHoldList=P.getLPSol(params,M,iteration,t,solDemList,solHoldList,IS_TRAINING)\n",
    "            obj[iteration] += val\n",
    "            \n",
    "            \n",
    "            #Grabbing exogenous data to construct data frame\n",
    "            recordDemandExo = (iteration,t,M.Bld_Net.demandamount.copy())\n",
    "            demandExoList.append(recordDemandExo)       \n",
    "            if (t==0):   \n",
    "                recordDonationExo = (iteration,0,list(np.array(M.bld_inv)[::params['MAX_AGE']]))\n",
    "                donationExoList.append(recordDonationExo)\n",
    "            \n",
    "            if (t<params['MAX_TIME']-1):\n",
    "                recordDonationExo = (iteration,t+1,M.donation.copy())\n",
    "                donationExoList.append(recordDonationExo)\n",
    "                \n",
    "            #Grabbing pre-decision state to construct data frame\n",
    "            recordSupplyPre = (iteration,t,M.bld_inv.copy())\n",
    "            supplyPreList.append(recordSupplyPre)\n",
    "                \n",
    "            \n",
    "            if IS_TRAINING:    \n",
    "                alpha,slopesList,updateVfaList = P.updateVFAs(params,M,iteration,t,d, slopesList,updateVfaList)\n",
    "                            \n",
    "            # build decision\n",
    "            dcsn = M.build_decision({'Hold': hld, 'Contribution': val})\n",
    "                    \n",
    "            M.transition_fn(dcsn)\n",
    "            \n",
    "            #Grabbing post-decision state to construct data frame\n",
    "            recordSupplyPost = (iteration,t,M.bld_inv.copy())\n",
    "            supplyPostList.append(recordSupplyPost)\n",
    "            \n",
    "            t += 1\n",
    "            # generate/read exogenous information \n",
    "            if (params['SAMPLING_DIST'] == 'P'):\n",
    "                exog_info = generate_exog_info_by_bloodtype_p(t, Bld_Net, params)\n",
    "            else:\n",
    "                exog_info = generate_exog_info_by_bloodtype(t, Bld_Net, params)\n",
    "            M.exog_info_fn(exog_info)\n",
    "            \n",
    "        \n",
    "        \n",
    "        # copy v to the parallel links\n",
    "        for t in params['Times']:\n",
    "            for hld in M.Bld_Net.holdnodes:\n",
    "                parArr = 1 * M.Bld_Net.varr[(t,hld, M.Bld_Net.supersink)]\n",
    "                M.Bld_Net.add_parallel(t,hld, M.Bld_Net.supersink, parArr)\n",
    "        \n",
    "          \n",
    "\n",
    "        # t_end = time.clock()\n",
    "        t_end = time.process_time()\n",
    "        recordSimu = (iteration,int(t_end-t_init),alpha,obj[iteration],(iteration<params['NUM_TRAINNING_ITER']))\n",
    "        simuList.append(recordSimu)\n",
    "       \n",
    "        # print(\"***Finishing iteration {} in {:.2f} secs. Total contribution: {:.2f}***\\n\".format(recordSimu[0],recordSimu[1],recordSimu[3]))\n",
    "        \n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "    #End of iterations\n",
    "    ###########################################################################################################################################\n",
    "\n",
    "\n",
    "    if (params['SAVE_VFA']):\n",
    "        pickling_on = open(params['NAME_SAVE_VFA_PICKLE'],\"wb\")\n",
    "        pickle.dump(M.Bld_Net, pickling_on)\n",
    "        pickling_on.close()\n",
    "\n",
    "    \n",
    "\n",
    "    ###########################################################################################################################################\n",
    "    #Computing stats and plots\n",
    "    ###########################################################################################################################################\n",
    "    dfDemandExo, dfDonationExo, dfSupplyPre, dfSupplyPost, dfSlopes, dfSolDem, dfSolHold,  dfSimu, dfUpdateVfa = convertToDfOutputLists(params,Bld_Net,demandExoList, donationExoList, supplyPreList, supplyPostList, slopesList, solDemList, solHoldList,  simuList, updateVfaList)\n",
    "\n",
    "    # print(dfDemandExo)\n",
    "\n",
    "    policy = params['USE_VFA'] and 'VFA-Based' or 'MYOPIC'\n",
    "    surge  = params['SURGE_PROB']>0 and \"SURGE_\"+str(params['SURGE_PROB']) or \"NO_SURGE\"\n",
    "    instance = \"Policy{}_{}_PEN_{:,}_ALPHA_{:.2f}\".format(policy,surge,params['BLOOD_FOR_ELECTIVE_PENALTY'],params['ALPHA'])\n",
    "\n",
    "    #Average Contribution\n",
    "    meanTesting = dfSimu.groupby('isTrainning')['ObjVal'].mean()[False]\n",
    "    stdevTesting = dfSimu.groupby('isTrainning')['ObjVal'].std(ddof = 0)[False]\n",
    "\n",
    "    # print(dfSimu.groupby('isTrainning')['ObjVal'])\n",
    "    # print(stdevTesting)\n",
    "    #Total Blood discarded\n",
    "    totalDiscarded = dfSolHold.loc[(dfSolHold.Age.astype(int)>params['MAX_AGE']-2)&(dfSolHold.Iteration>=params['NUM_TRAINNING_ITER']),:].copy()['Value'].sum()\n",
    "\n",
    "    #Total Donation\n",
    "    totalDonation = dfDonationExo[dfDonationExo.Iteration>=params['NUM_TRAINNING_ITER']].copy()['DonationValue'].sum()\n",
    "\n",
    "    #Coverage \n",
    "    dfCoverage = dfSolDem.groupby(['BloodTypeD', 'Urgency','Iteration',  'Time'])['Value'].sum()\n",
    "    dfCoverage.index = dfCoverage.index.rename(\"Bloodtype\", level=0)   \n",
    "    dfCoverage = pd.concat([dfCoverage,dfDemandExo.groupby(['Bloodtype', 'Urgency','Iteration',  'Time'])['DemandValue'].sum()],axis=1)\n",
    "    dfCoverage['Ratio']= dfCoverage['Value']/ dfCoverage['DemandValue']\n",
    "    \n",
    "    \n",
    "    dfCoverage_agg_ite = dfCoverage.groupby(['Bloodtype', 'Urgency','Iteration'])['Ratio'].mean().reset_index()\n",
    "\n",
    "    numTra = params['NUM_TRAINNING_ITER']\n",
    "    dfCoverage_agg_test = dfCoverage_agg_ite.query('Iteration >= @numTra')\n",
    "    dfPrintIte=dfCoverage_agg_test.pivot_table('Ratio',index='Bloodtype',columns='Urgency')\n",
    "\n",
    "    \n",
    "\n",
    "    finalCoverage=dfCoverage_agg_test.groupby('Urgency')['Ratio'].mean()\n",
    "\n",
    "    coverage = \"Average Coverage: -  Urgent: {:.2f} Elective: {:.2f} Avg: {:.2f}\".format(finalCoverage['Urgent'],finalCoverage['Elective'],dfCoverage_agg_ite['Ratio'].mean())\n",
    "    \n",
    "    #dfUtility = dfCoverage.query('Iteration >= @numTra').copy().reset_index()\n",
    "    #dfUtility['Weight']=-1\n",
    "    #dfUtility['Score']=0\n",
    "    #dfUtility.loc[dfUtility.Urgency==\"Elective\",'Weight']=1\n",
    "    #dfUtility.loc[dfUtility.Urgency==\"Urgent\",'Weight']=100\n",
    "    #dfUtility.loc[(dfUtility.Urgency==\"Urgent\") & (dfUtility.Ratio>.9),'Score']=1\n",
    "    #sumRatio=(dfUtility['Ratio']*dfUtility['Weight']).sum()\n",
    "    #sumWeight=(dfUtility['Weight']).sum()\n",
    "    #sumScore=(dfUtility['Score']).sum()\n",
    "    #utility=sumRatio/sumWeight\n",
    "    \n",
    "    # print('final_cov',finalCoverage)\n",
    "    # print('discard', totalDiscarded)\n",
    "    # print('donat', totalDonation)\n",
    "    #Utility function\n",
    "    # utility=(params['WEIGHT_URGENT']*round(finalCoverage['Urgent'],2)+params['WEIGHT_ELECTIVE']*round(finalCoverage['Elective'],2))*100\n",
    "    # modifiedUtil=utility-params['WEIGHT_DISCARDED']*100*round(totalDiscarded/totalDonation,2)\n",
    "\n",
    "    idx = pd.IndexSlice\n",
    "    ite_TES =  np.arange(0, params['NUM_TESTING_ITER'], 1) + params['NUM_TRAINNING_ITER']\n",
    "    dfCoverage=dfCoverage[dfCoverage.DemandValue>0].copy()\n",
    "    utility_lst = []\n",
    "    \n",
    "    for i in ite_TES:\n",
    "        ite_TES_i = np.array([i,])\n",
    "        # print(ite_TES_i)\n",
    "        uncoverU = dfCoverage.loc[idx[:,['Urgent'],ite_TES_i,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,['Urgent'],ite_TES_i,:],['Value']].values.sum() \n",
    "        uncoverE = dfCoverage.loc[idx[:,['Elective'],ite_TES_i,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,['Elective'],ite_TES_i,:],['Value']].values.sum() \n",
    "        uncoverT = dfCoverage.loc[idx[:,:,ite_TES_i,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,:,ite_TES_i,:],['Value']].values.sum() \n",
    "\n",
    "        demandU = dfCoverage.loc[idx[:,['Urgent'],ite_TES_i,:],['DemandValue']].values.sum() \n",
    "        demandE = dfCoverage.loc[idx[:,['Elective'],ite_TES_i,:],['DemandValue']].values.sum() \n",
    "        demandT = dfCoverage.loc[idx[:,:,ite_TES_i,:],['DemandValue']].values.sum() \n",
    "\n",
    "\n",
    "        discard_i = dfSolHold.loc[(dfSolHold.Age.astype(int)>params['MAX_AGE']-2)&(dfSolHold.Iteration==i),:].copy()['Value'].sum()\n",
    "        utility=params['WEIGHT_URGENT']*(demandU-uncoverU)+params['WEIGHT_ELECTIVE']*(demandE-uncoverE)\n",
    "        modifiedUtil=utility-(params['WEIGHT_DISCARDED']*discard_i)\n",
    "        utility_lst.append(modifiedUtil)\n",
    "    # print(utility_lst)\n",
    "    # print(np.mean(utility_lst))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #####3\n",
    "\n",
    "\n",
    "\n",
    "    # dfCoverage=dfCoverage[dfCoverage.DemandValue>0].copy()\n",
    "    # uncoverU = dfCoverage.loc[idx[:,['Urgent'],ite_TES,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,['Urgent'],ite_TES,:],['Value']].values.sum() \n",
    "    # uncoverE = dfCoverage.loc[idx[:,['Elective'],ite_TES,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,['Elective'],ite_TES,:],['Value']].values.sum() \n",
    "    # uncoverT = dfCoverage.loc[idx[:,:,ite_TES,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,:,ite_TES,:],['Value']].values.sum() \n",
    "\n",
    "    # demandU = dfCoverage.loc[idx[:,['Urgent'],ite_TES,:],['DemandValue']].values.sum() \n",
    "    # demandE = dfCoverage.loc[idx[:,['Elective'],ite_TES,:],['DemandValue']].values.sum() \n",
    "    # demandT = dfCoverage.loc[idx[:,:,ite_TES,:],['DemandValue']].values.sum() \n",
    "\n",
    "    # utility=(params['WEIGHT_URGENT']*(demandU-uncoverU)+params['WEIGHT_ELECTIVE']*(demandE-uncoverE))/params['NUM_TESTING_ITER']\n",
    "    # modifiedUtil=utility-(params['WEIGHT_DISCARDED']*totalDiscarded)/params['NUM_TESTING_ITER']\n",
    "    # print(modifiedUtil)\n",
    "\n",
    "    # print(sum(uncoverU_lst), sum(uncoverE_lst), sum(uncoverT_lst))\n",
    "    # print(uncoverU, uncoverE, uncoverT)\n",
    "    # print(sum(demandU_lst), sum(demandE_lst), sum(demandT_lst))\n",
    "    # print(demandU, demandE, demandT)   \n",
    "\n",
    "\n",
    "    # print(f\"wefwe {demandT}\")\n",
    "    # print(f\"Average Total Demand (urgent): {demandU/params['NUM_TESTING_ITER']:.2f}\")\n",
    "    # print(f\"Average Total Demand Uncovered (urgent): {uncoverU/params['NUM_TESTING_ITER']:.2f}\"\n",
    "    # print(f\"Average Total Demand (elective): {demandE/params['NUM_TESTING_ITER']:.2f}\")\n",
    "    # print(f\"Average Total Demand Uncovered (elective): {uncoverE/params['NUM_TESTING_ITER']:.2f}\"\n",
    "    # print(f\"Average units of blood discarded: {totalDiscarded/params['NUM_TESTING_ITER']:.2f}\")\n",
    "    # print('demandU', demandU)\n",
    "    # print('demandE', demandE)\n",
    "    # print('totalDis', totalDiscarded)\n",
    "\n",
    "    if params['SHOW_PLOTS'] == True:\n",
    "\n",
    "        \n",
    "        ###########################################################################################################################################\n",
    "        #Figure 1 - Total Contribution along iterations\n",
    "        ite = np.arange(0, params['NUM_ITER'], 1)\n",
    "        ite_TRA =  np.arange(0, params['NUM_TRAINNING_ITER'], 1)\n",
    "        ite_TES =  np.arange(0, params['NUM_TESTING_ITER'], 1) + params['NUM_TRAINNING_ITER']\n",
    "        \n",
    "        fig_ite, ax_ite = plt.subplots(figsize=(16,8))\n",
    "        ax_ite.plot(ite,dfSimu['ObjVal'],'g-',label='_nolegend_')\n",
    "        ax_ite.plot(ite_TRA,dfSimu['ObjVal'][ite_TRA],'g-',label=\"Training\",marker='o')\n",
    "        ax_ite.plot(ite_TES,dfSimu['ObjVal'][ite_TES],'b-',label=\"Testing\",marker='o')\n",
    "        ax_ite.hlines(meanTesting, ite_TES[0], ite_TES[-1], color='b',linestyle='--',label=\"Avg Testing\",linewidth=4)\n",
    "        \n",
    "        ax_ite.axvline(ite_TES[0], 0, 1, color='k',linestyle=':')\n",
    "        ax_ite.legend()\n",
    "        ax_ite.set_xlabel('Iterations',fontsize=12)\n",
    "        ax_ite.set_ylabel('$',fontsize=12)\n",
    "        #ax_ite.set_ylim([20000,34000])\n",
    "        ax_ite.set_title(\"Figure 1: Policy {}_{} - Total contributions \\n Avg total contribution during TESTING iterations: ${:,}\\n Final utility: {:.2f}\".format(policy,surge,meanTesting,modifiedUtil))\n",
    "        ax_ite.set_xticks(ite)\n",
    "        ax_ite.set_xticklabels(list(ite_TRA)+list(np.arange(0, params['NUM_TESTING_ITER'], 1)))\n",
    "        for c in ite_TES:\n",
    "            ax_ite.get_xticklabels()[c].set_color(\"b\")\n",
    "        ###########################################################################################################################################\n",
    "\n",
    "        \n",
    "        ###########################################################################################################################################\n",
    "        #Figure 2 - Exogenous processes - Demand and Donation\n",
    "        fig_exo, ax_exo = plt.subplots(2,1,figsize=(16,8),sharex=True)\n",
    "        dfDemandExoP = dfDemandExo[dfDemandExo.Iteration>=params['NUM_TRAINNING_ITER']].copy()\n",
    "        dfDemandExoP['Iteration'] = dfDemandExoP['Iteration'] - params['NUM_TRAINNING_ITER']\n",
    "        dfPrintDemand = dfDemandExoP.pivot_table('DemandValue',index='Time',columns='Iteration',aggfunc='sum')\n",
    "\n",
    "        # print(dfDemandExoP.pivot_table('DemandValue',index='Time',columns='Iteration',aggfunc='sum'))\n",
    "\n",
    "        \n",
    "        l=dfPrintDemand.plot(ax=ax_exo[0],title=\"Total Demand - {}\".format(surge),legend=False)\n",
    "\n",
    "        dfDonationExoP = dfDonationExo[dfDonationExo.Iteration>=params['NUM_TRAINNING_ITER']].copy()\n",
    "        dfDonationExoP['Iteration'] = dfDonationExoP['Iteration'] - params['NUM_TRAINNING_ITER']\n",
    "        dfPrintDonation = dfDonationExoP.pivot_table('DonationValue',index='Time',columns='Iteration',aggfunc='sum')\n",
    "        dfPrintDonation.plot(ax=ax_exo[1],title=\"Total Donation\",legend=False)\n",
    "        ax_exo[1].set_xlabel(\"Time period\",fontsize=12)\n",
    "        ax_exo[0].set_ylabel(\"Units\",fontsize=12)\n",
    "        ax_exo[1].set_ylabel(\"Units\",fontsize=12)\n",
    "        \n",
    "        fig_exo.legend(l,labels=list(np.arange(0, params['NUM_TESTING_ITER'], 1)),title=\"Iteration\",loc=\"center right\",fancybox=True, shadow=True)\n",
    "        fig_exo.suptitle(\"Figure 2 - Exogenous processes along the testing iterations\")\n",
    "        ###########################################################################################################################################\n",
    "\n",
    "        \n",
    "        \n",
    "        dfInv = dfSupplyPre[dfSupplyPre.Iteration>=params['NUM_TRAINNING_ITER']].copy()\n",
    "        dfInv['Iteration'] = dfInv['Iteration'] - params['NUM_TRAINNING_ITER']\n",
    "        \n",
    "        ###########################################################################################################################################\n",
    "        #Figure 3 - Pre decision inventory levels by age\n",
    "        fig_inv, ax_inv = plt.subplots(3,1,figsize=(16,10),sharex=True)\n",
    "        for age in [0,1,2]:\n",
    "\n",
    "            strage=str(age)\n",
    "\n",
    "            dfPrint = dfInv[dfInv.Age == strage].pivot_table('PreInv',index=['Time'],columns=['Iteration'],aggfunc='sum')\n",
    "            l=dfPrint.plot(ax=ax_inv[age],legend=False)\n",
    "\n",
    "\n",
    "            dfPrintAvg = dfInv[dfInv.Age == strage].groupby(['Time','Iteration'])['PreInv'].sum()\n",
    "            dfPrintAvg = dfPrintAvg.groupby('Time').mean()\n",
    "            avg_line = ax_inv[age].plot(dfPrintAvg.index,dfPrintAvg.values,'k',linestyle=':',marker='s',markersize='12',label='Average')\n",
    "            ax_inv[age].set_title(\"Age: {} - Avg inventory level: {:.0f}\".format(age,dfPrintAvg.values.mean()))\n",
    "            ax_inv[age].set_ylabel(\"Units\",fontsize=12)\n",
    "\n",
    "        ax_inv[2].set_xlabel(\"Time period\",fontsize=12)\n",
    "        fig_inv.suptitle(\"Figure 3 - Policy {}_{} \\n Pre-decision  inventory level all blood types\".format(policy,surge))\n",
    "        fig_inv.legend([l,avg_line],labels=list(np.arange(0, params['NUM_TESTING_ITER'], 1))+[\"Avg\"],title=\"Iteration\",loc='center right',fancybox=True, shadow=True, ncol=1)\n",
    "        ###########################################################################################################################################\n",
    "\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        #Figure 4 - Pre decision inventory levels by bloodtype\n",
    "        fig_inv_blood, ax_inv_blood = plt.subplots(4,2,figsize=(16,10),sharex=True)\n",
    "        row = -1\n",
    "        for m,b in enumerate(params['Bloodtypes']):\n",
    "\n",
    "            col= (m)%2\n",
    "            if col == 0:\n",
    "                row+=1\n",
    "                ax_inv_blood[row,col].set_ylabel(\"Units\",fontsize=8)\n",
    "\n",
    "            dfPrint = dfInv[dfInv.BloodType == b].pivot_table('PreInv',index=['Time'],columns=['Iteration'],aggfunc='sum')\n",
    "            l=dfPrint.plot(ax=ax_inv_blood[row,col],legend=False)\n",
    "\n",
    "            dfPrintAvg = dfInv[dfInv.BloodType == b].groupby(['Time','Iteration'])['PreInv'].sum()\n",
    "            dfPrintAvg = dfPrintAvg.groupby('Time').mean()\n",
    "\n",
    "            avg_line =  ax_inv_blood[row,col].plot(dfPrintAvg.index,dfPrintAvg.values,'k',linestyle=':',marker='s',markersize='10',label='Average')\n",
    "\n",
    "            ax_inv_blood[row,col].set_title(\"Bloodtype: {}  - Avg inventory level: {:.0f}\".format(b,dfPrintAvg.values.mean()),fontsize=8)\n",
    "            ax_inv_blood[row,col].set_xlabel(\"Time Period\",fontsize=8)\n",
    "\n",
    "        fig_inv_blood.suptitle(\"Figure 4 - Policy {}_{} \\n Pre-decision  inventory level all ages\".format(policy,surge))\n",
    "        fig_inv_blood.legend([l,avg_line],labels=list(np.arange(0, params['NUM_TESTING_ITER'], 1))+[\"Avg\"],loc=\"center right\", title=\"Iteration\")\n",
    "        ###########################################################################################################################################\n",
    "\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        #Figure 5 - Pre decision inventory levels \n",
    "        dfPrintAvg = dfInv.groupby(['Time','Iteration'])['PreInv'].sum()\n",
    "        dfPrintAvg = dfPrintAvg.groupby('Time').mean()\n",
    "        fig_inv_total, ax_inv_total = plt.subplots(figsize=(16,8))\n",
    "        dfPrint = dfInv.pivot_table('PreInv',index=['Time'],columns=['Iteration'],aggfunc='sum')\n",
    "        dfPrint.plot(ax=ax_inv_total,legend=True)\n",
    "        first_legend = ax_inv_total.legend(title=\"Iteration\")\n",
    "        avg_line = ax_inv_total.plot(dfPrintAvg.index,dfPrintAvg.values,'k',linestyle=':',marker='s',markersize='12',label='Average')\n",
    "        ax_inv_total.legend(title=\"Iteration\")\n",
    "        ax_inv_total.set_xlabel(\"Time period\")\n",
    "        ax_inv_total.set_ylabel(\"Units\")\n",
    "        fig_inv_total.suptitle(\"Figure 5 - Policy {}_{} \\n Pre-decision inventory level all blood types and ages \\n Average inventory level across time periods: {:.0f}\".format(policy,surge,dfPrintAvg.values.mean()))\n",
    "        ###########################################################################################################################################\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        #Figure 6 - Discarded blood during testing iterations\n",
    "        dfDiscarded = dfSolHold.loc[(dfSolHold.Age.astype(int)>params['MAX_AGE']-2)&(dfSolHold.Iteration>=params['NUM_TRAINNING_ITER']),:].copy()\n",
    "        dfDiscarded = dfDiscarded.groupby(['BloodTypeS','Time'])['Value'].sum().reset_index()\n",
    "        dfDiscarded['Prop']=100*dfDiscarded['Value']/totalDonation\n",
    "        \n",
    "\n",
    "        y_a = dfDiscarded.BloodTypeS.unique()\n",
    "        x_a = dfDiscarded.Time.unique()\n",
    "        discarded_matrix = np.reshape(np.array(dfDiscarded['Value']), (-1, len(x_a)))\n",
    "    \n",
    "        \n",
    "        fig_dis, ax_dis = plt.subplots(figsize=(16,8))  \n",
    "        im = ax_dis.imshow(discarded_matrix, cmap='hot_r',origin='lower',aspect='auto',alpha=.9)\n",
    "        cbar = ax_dis.figure.colorbar(im, ax=ax_dis,label='Units of blood')  \n",
    "        ax_dis.set_xticks(np.arange(len(x_a)))\n",
    "        ax_dis.set_yticks(np.arange(len(y_a)))\n",
    "        ax_dis.set_xticklabels(x_a)\n",
    "        ax_dis.set_yticklabels(y_a)\n",
    "        ax_dis.set_xlabel(\"Time Period\")\n",
    "        ax_dis.set_title(\"Figure 6 - Policy {}_{} \\n Total discarded blood during TESTING iterations\\n Proportion of blood discarded: {:.2f}%\".format(policy,surge,totalDiscarded*100/totalDonation))\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        #Figure 7 - Demand Coverage - Testing iterations\n",
    "        fig_tes, ax_tes = plt.subplots(figsize=(16,8))   \n",
    "        ax_tes.plot(dfPrintIte['Urgent'],marker='o', label = 'Urgent')\n",
    "        ax_tes.plot(dfPrintIte['Elective'],marker='o', label = 'Elective')\n",
    "        ax_tes.set_title(\"Figure 7 -Policy {}_{} \\n Average coverage of demand by blood type and urgency level during TESTING iterations\\n {} Coverage utility: {:.0f}\".format(policy,surge,coverage,utility))\n",
    "        ax_tes.set_ylabel(\"Coverage ratio\")\n",
    "        ax_tes.legend(title=\"Urgency level\",loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True, ncol=1)\n",
    "        ###########################################################################################################################################\n",
    "\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        #Figure 8 - Demand Coverage - Along Blood types\n",
    "        iteS = np.arange(0, params['NUM_ITER'], 1)\n",
    "        if True:\n",
    "            \n",
    "            #selectedIte = sorted(list(set([0,5,10,19]) ))\n",
    "            selectedIte = sorted(list(set([0,5,10,19]) & set(iteS)))\n",
    "            fig_cover, ax_cover = plt.subplots(1,len(selectedIte),figsize=(16,8),sharey=True)\n",
    "\n",
    "            \n",
    "\n",
    "            for i,ite in enumerate(selectedIte):\n",
    "                dfPrintIte = dfCoverage_agg_ite[dfCoverage_agg_ite.Iteration==ite]\n",
    "                dfPrintIte=dfPrintIte.pivot_table('Ratio',index='Bloodtype',columns='Urgency')\n",
    "\n",
    "                typIte='TES'\n",
    "                if ite <params['NUM_TRAINNING_ITER']:\n",
    "                    typIte='TRA'\n",
    "\n",
    "                \n",
    "                if len(selectedIte)==1:\n",
    "                    ax_cover.plot(dfPrintIte['Urgent'],marker='o', label = 'Urgent')\n",
    "                    ax_cover.plot(dfPrintIte['Elective'],marker='o', label = 'Elective')\n",
    "                    ax_cover.set_title(\"Iteration {} ({})\".format(ite,typIte))\n",
    "                else:\n",
    "                    ax_cover[i].plot(dfPrintIte['Urgent'],marker='o', label = 'Urgent')\n",
    "                    ax_cover[i].plot(dfPrintIte['Elective'],marker='o', label = 'Elective')\n",
    "                    ax_cover[i].set_title(\"Iteration {} ({})\".format(ite,typIte))\n",
    "            \n",
    "                fig_cover.suptitle(\"Figure 8 - Policy {}-{} \\n Average coverage of demand by blood type and urgency level for different iterations\".format(policy,surge))\n",
    "\n",
    "            if len(selectedIte)==1:\n",
    "                ax_cover.set_ylabel(\"Coverage ratio\")\n",
    "                ax_cover.legend(title=\"Urgency level\",loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True, ncol=1)\n",
    "            else:\n",
    "                ax_cover[0].set_ylabel(\"Coverage ratio\")\n",
    "                ax_cover[len(selectedIte)-1].legend(title=\"Urgency level\",loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True, ncol=1)    \n",
    "        ###########################################################################################################################################\n",
    "\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        #Figure 9 - Demand Coverage - Along time periods\n",
    "        if True:\n",
    "            dfCoverage_agg_ite = dfCoverage.groupby(['Time', 'Urgency','Iteration'])['Ratio'].mean().reset_index()\n",
    "            #selectedIte = sorted(list(set([0,5,10,19]) ))\n",
    "            selectedIte = sorted(list(set([0,5,10,19]) & set(iteS)))\n",
    "            fig_cover_ite, ax_cover_ite = plt.subplots(1,len(selectedIte),figsize=(16,8),sharey=True,sharex=True)\n",
    "            for i,ite in enumerate(selectedIte):\n",
    "                dfPrintIte = dfCoverage_agg_ite[dfCoverage_agg_ite.Iteration==ite]\n",
    "                dfPrintIte=dfPrintIte.pivot_table('Ratio',index='Time',columns='Urgency')\n",
    "\n",
    "                typIte='TES'\n",
    "                if ite <params['NUM_TRAINNING_ITER']:\n",
    "                    typIte='TRA'\n",
    "                \n",
    "                if len(selectedIte)==1:\n",
    "                    ax_cover_ite.plot(dfPrintIte['Urgent'],marker='o', label = 'Urgent')\n",
    "                    ax_cover_ite.plot(dfPrintIte['Elective'],marker='o', label = 'Elective')\n",
    "                    ax_cover_ite.set_title(\"Iteration {} ({})\".format(ite,typIte))\n",
    "                    ax_cover_ite.set_xticks(list(range(0,params['MAX_TIME'],2)))\n",
    "                    ax_cover_ite.set_xticklabels(list(range(0,params['MAX_TIME'],2)))\n",
    "                    ax_cover_ite.set_xlabel(\"Time Period\")\n",
    "                else:\n",
    "                    ax_cover_ite[i].plot(dfPrintIte['Urgent'],marker='o', label = 'Urgent')\n",
    "                    ax_cover_ite[i].plot(dfPrintIte['Elective'],marker='o', label = 'Elective')\n",
    "                    ax_cover_ite[i].set_title(\"Iteration {} ({})\".format(ite,typIte))\n",
    "                    ax_cover_ite[i].set_xticks(list(range(0,params['MAX_TIME'],2)))\n",
    "                    ax_cover_ite[i].set_xticklabels(list(range(0,params['MAX_TIME'],2)))\n",
    "                    ax_cover_ite[i].set_xlabel(\"Time Period\")\n",
    "\n",
    "                fig_cover_ite.suptitle(\"Figure 9 - Policy {}-{} \\n Average coverage of demand by time period and urgency level for different iterations\".format(policy,surge))\n",
    "\n",
    "            if len(selectedIte)==1:\n",
    "                ax_cover_ite.set_ylabel(\"Coverage ratio\")\n",
    "                ax_cover_ite.legend(title=\"Urgency level\",loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True, ncol=1)\n",
    "            else:\n",
    "                ax_cover_ite[0].set_ylabel(\"Coverage ratio\")\n",
    "                ax_cover_ite[len(selectedIte)-1].legend(title=\"Urgency level\",loc='center left', bbox_to_anchor=(1, 0.5),fancybox=True, shadow=True, ncol=1)\n",
    "\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        #Figure 10 - Histogram Demand Coverage - Along time periods       \n",
    "        idx = pd.IndexSlice\n",
    "        dfCoverage=dfCoverage[dfCoverage.DemandValue>0].copy()\n",
    "\n",
    "        uncoverU = dfCoverage.loc[idx[:,['Urgent'],ite_TES,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,['Urgent'],ite_TES,:],['Value']].values.sum() \n",
    "        uncoverE = dfCoverage.loc[idx[:,['Elective'],ite_TES,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,['Elective'],ite_TES,:],['Value']].values.sum() \n",
    "        uncoverT = dfCoverage.loc[idx[:,:,ite_TES,:],['DemandValue']].values.sum() - dfCoverage.loc[idx[:,:,ite_TES,:],['Value']].values.sum() \n",
    "\n",
    "        demandU = dfCoverage.loc[idx[:,['Urgent'],ite_TES,:],['DemandValue']].values.sum() \n",
    "        demandE = dfCoverage.loc[idx[:,['Elective'],ite_TES,:],['DemandValue']].values.sum() \n",
    "        demandT = dfCoverage.loc[idx[:,:,ite_TES,:],['DemandValue']].values.sum() \n",
    "        \n",
    "\n",
    "        fig_hist, ax_hist = plt.subplots(1,3,figsize=(16,8),sharey=True,sharex=True)\n",
    "        ax_hist[0].hist(dfCoverage.loc[idx[:,['Urgent'],ite_TES,:],['Ratio']].values, bins=11,color='tab:blue')\n",
    "        ax_hist[0].set_title(\"Urgent\")\n",
    "        ax_hist[0].set_ylabel(\"Count\")\n",
    "        ax_hist[0].set_xlim([0,1])\n",
    "        ax_hist[0].annotate('Uncovered Demand: {:,}\\n Total Demand: {:,}'.format(int(uncoverU),demandU),xy=(.8, .975), xycoords='axes fraction',horizontalalignment='right', verticalalignment='top',fontsize=12)\n",
    "        \n",
    "        ax_hist[1].hist(dfCoverage.loc[idx[:,['Elective'],ite_TES,:],['Ratio']].values, bins=11,color='tab:orange')\n",
    "        ax_hist[1].set_title(\"Elective\")\n",
    "        ax_hist[1].set_xlabel(\"Coverage Ratio\")\n",
    "        ax_hist[1].annotate('Uncovered Demand: {:,}\\n Total Demand: {:,}'.format(int(uncoverE),demandE),xy=(.8, .975), xycoords='axes fraction',horizontalalignment='right', verticalalignment='top',fontsize=12)\n",
    "\n",
    "\n",
    "        ax_hist[2].hist(dfCoverage.loc[idx[:,:,ite_TES,:],['Ratio']].values, bins=11,color='tab:gray')\n",
    "        ax_hist[2].set_title(\"Total\")\n",
    "        ax_hist[2].annotate('Uncovered Demand: {:,}\\n Total Demand: {:,}'.format(int(uncoverT),demandT),xy=(.8, .975), xycoords='axes fraction',horizontalalignment='right', verticalalignment='top',fontsize=12)\n",
    "\n",
    "        fig_hist.suptitle(\"Figure 10 - Policy {}-{} \\n Histogram of blood coverage - All TESTING iterations and time periods\\n {} Coverage utility: {:.0f}\".format(policy,surge,coverage,utility))\n",
    "        ###########################################################################################################################################\n",
    "        \n",
    "        if params['SAVE_PLOTS']:\n",
    "            fig_ite.savefig('{}_Figure1.pdf'.format(instance))\n",
    "            fig_exo.savefig('{}_Figure2.pdf'.format(instance))\n",
    "            fig_inv.savefig('{}_Figure3.pdf'.format(instance))\n",
    "            fig_inv_blood.savefig('{}_Figure4.pdf'.format(instance))\n",
    "            fig_inv_total.savefig('{}_Figure5.pdf'.format(instance))\n",
    "            fig_dis.savefig('{}_Figure6.pdf'.format(instance))\n",
    "            fig_tes.savefig('{}_Figure7.pdf'.format(instance))\n",
    "            fig_cover.savefig('{}_Figure8.pdf'.format(instance))\n",
    "            fig_cover_ite.savefig('{}_Figure9.pdf'.format(instance))\n",
    "            fig_hist.savefig('{}_Figure10.pdf'.format(instance))\n",
    "\n",
    "        if params['SHOW_PLOTS']:\n",
    "            plt.show()\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "    # Printing the final results\n",
    "\n",
    "\n",
    "    res_dict = dict()\n",
    "\n",
    "    # print(\"\\n*******************************************************************************************\")\n",
    "    res_dict[\"Policy: \"] = (policy,surge)\n",
    "    res_dict['name'] = instance\n",
    "    res_dict[\"coverage\"] = coverage\n",
    "    res_dict[\"Percentage of blood discarded: \"] = totalDiscarded*100/totalDonation\n",
    "    res_dict[\"Average Total Demand (urgent): \"] = demandU/params['NUM_TESTING_ITER']\n",
    "    res_dict[\"Average Total Demand Uncovered (urgent): \"] = uncoverU/params['NUM_TESTING_ITER']\n",
    "    res_dict[\"Average Total Demand (elective): \"] = demandE/params['NUM_TESTING_ITER']\n",
    "    res_dict[\"Average Total Demand Uncovered (elective): \"] = uncoverE/params['NUM_TESTING_ITER']\n",
    "    res_dict[\"Average units of blood discarded: \"]=totalDiscarded/params['NUM_TESTING_ITER']\n",
    "    res_dict[\"Average total contribution during TESTING iterations\"] = meanTesting\n",
    "    res_dict[\"StDev total contribution during TESTING iterations\"] = stdevTesting\n",
    "    res_dict[\"Average utility: \"] = np.mean(utility_lst)\n",
    "    res_dict[\"StDev utility\"] = np.std(utility_lst)\n",
    "    \n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47adb57e-c1cd-4128-b21d-1aa049bdf420",
   "metadata": {},
   "source": [
    "## Utility Function\n",
    "This is the objective function we are trying to optimise (in expectation). It is calculated for a particular traning run as\n",
    "$$\n",
    "\\text{Utility} = c^{urgent} \\times cov_u + c^{elective} \\times cov_e + c^{discard} \\times discard,\n",
    "$$\n",
    "where $cov_u$ is the number of urgent demands covered over the time horizon, $cov_e$ is the number of elective demands covered over the time horizon and $discard$ is the number of units of blood discarded over the time horizon.\n",
    "\n",
    "$c^{urgent}>0$, $c^{elective} >0$ and $c^{discard}<0$ are inputs to the problem.\n",
    "\n",
    "Utility will be reported as an averaged over the number of testing iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85878581-4abc-46d1-a31a-7be7aa360fc6",
   "metadata": {},
   "source": [
    "## Figure Descriptions\n",
    "\n",
    "- Figure 1: Total Contribution along iterations, When using a VFA-based policy, we will plot both training and testing iterations. When using a Myopic policy, we will only plot the testing iterations.\n",
    "- Figure 2: Exogenous processes  during testing iterations, Total Demand and Donation along time periods.\n",
    "- Figure 3: predecision inventory levels during testing iterations by blood age along time periods\n",
    "- Figure 4: predecision inventory levels during testing iterations by blood type along time periods\n",
    "- Figure 5: Total predecision inventory levels\t\t\n",
    "- Figure 6: Discarded blood during testing iterations\t\t\n",
    "- Figure 7: Demand coverage during testing iterations along blood types\t\t\n",
    "- Figure 8: Demand coverage for selected iterations, along lood types \t\t\n",
    "- Figure 9: Demand coverage for selected  iterations, along time periods\t\t\n",
    "- Figure 10: Histogram of coverage ratios during testing iterations\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7eb49-20ec-477c-8b63-97d3c517f9c9",
   "metadata": {},
   "source": [
    "## Parameter Descriptions:\n",
    "\n",
    "- `BLOOD_FOR_ELECTIVE_PENALTY`:\tPenalty for covering elective demand. Used to guide the myopic policy.\t\n",
    "- `SURGE_PROB`:\tProbability that a surge in demand might happen, $p^{surge}$.\n",
    "- `NUM_TRAINNING_ITER`:\tNumber of trainning iterations, $n^{train}$. Used in the VFA-based policy (`USE_VFA` = `True`). It is going to be ignored when `USE_VFA` is set to `False`\t\n",
    "- `NUM_TESTING_ITER`: Number of testing iterations, $n^{test}$.\n",
    "- `USE_VFA`: Parameter to indicate if  we should use a VFA-based policy. Set it to `True` if you want to use a VFA and set it to `False` if you want a Myopic policy.\t\n",
    "- `ALPHA`: The stepsize parameter to update the VFA, $\\alpha$. It is going to be ignored when `USE_VFA` is set to `False`\t\n",
    "- `SAVE_PLOTS`:\tSet to `True` if you want to save the plots to PDF files\n",
    "- `URGENT_DEMAND_BONUS`: is the weight $c^{urgent}$, used in the utility function\n",
    "- `ELECTIVE_DEMAND_BONUS`: is the weight $c^{elective}$, used in the utility function\n",
    "- `DISCARD_BLOOD_PENALTY`: is the weight $c^{discard}$, used in the utility function\n",
    "- `SHOW_PLOTS`: Set to `True` if you want to show plots of the figures described below, if `False` will just return dictionary of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9070143b-5bfa-4912-a26e-9df7d55c0835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************Started Main*****************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Policy: ': ('VFA-Based', 'SURGE_0.5'),\n",
       " 'name': 'PolicyVFA-Based_SURGE_0.5_PEN_0_ALPHA_0.25',\n",
       " 'coverage': 'Average Coverage: -  Urgent: 0.95 Elective: 0.77 Avg: 0.85',\n",
       " 'Percentage of blood discarded: ': 0.6907545164718385,\n",
       " 'Average Total Demand (urgent): ': 284.5,\n",
       " 'Average Total Demand Uncovered (urgent): ': 32.5,\n",
       " 'Average Total Demand (elective): ': 327.5,\n",
       " 'Average Total Demand Uncovered (elective): ': 111.0,\n",
       " 'Average units of blood discarded: ': 6.5,\n",
       " 'Average total contribution during TESTING iterations': 6321.75,\n",
       " 'StDev total contribution during TESTING iterations': 238.25,\n",
       " 'Average utility: ': 6321.75,\n",
       " 'StDev utility': 238.25}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_dict = {\n",
    "        'BLOOD_FOR_ELECTIVE_PENALTY': 0,\n",
    "        'SURGE_PROB': 0.5,\n",
    "        'NUM_TRAINNING_ITER': 1,\n",
    "        'NUM_TESTING_ITER': 2,\n",
    "        'USE_VFA': True,\n",
    "        'ALPHA': 0.25,\n",
    "        'SAVE_PLOTS': False,\n",
    "        'URGENT_DEMAND_BONUS': 10, \n",
    "        'ELECTIVE_DEMAND_BONUS': 2.5,\n",
    "        'DISCARD_BLOOD_PENALTY': -3,\n",
    "        'SHOW_PLOTS': False\n",
    "       }\n",
    "# this line runs everything for the given parameters.\n",
    "display(Main(param_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c69ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
